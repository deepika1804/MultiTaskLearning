{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_obtain_input_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c88e90befe2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimagenet_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_obtain_input_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhe_normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#import matplotlib.pyplot as plt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_obtain_input_shape'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.layers import GlobalAveragePooling2D, Add, concatenate, Lambda, Input, Layer, Dense, Conv2D \n",
    "from keras.layers import MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils, Sequence\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.preprocessing.image import apply_transform, transform_matrix_offset_center, flip_axis\n",
    "from keras.applications.imagenet_utils import preprocess_input, _obtain_input_shape\n",
    "from keras.initializers import he_normal\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.metrics import log_loss\n",
    "\n",
    "# from load_cifar10 import load_cifar10_data\n",
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat, savemat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation\n",
    "\n",
    "def densenet(num_classes, input_shape):\n",
    "    \n",
    "    def NiNBlock(kernel, mlps, strides):\n",
    "        def inner(x):\n",
    "            l = Conv2D(mlps[0], kernel, strides=strides, padding='same')(x)\n",
    "            l = Activation('relu')(l)\n",
    "            for size in mlps[1:]:\n",
    "                l = Conv2D(size, 1, strides=[1,1])(l)\n",
    "                l = Activation('relu')(l)\n",
    "            return l\n",
    "        return inner\n",
    "\n",
    "\n",
    "    def get_model(img_rows, img_cols,rgb):\n",
    "        img = Input(shape=(img_rows, img_cols, rgb))\n",
    "        l1 = NiNBlock(7, [96, 96, 96], [2,2])(img)\n",
    "        l1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(l1)\n",
    "    #     l1 = Dropout(0.7)(l1)\n",
    "\n",
    "        l2 = NiNBlock(5, [256, 256, 256], [2,2])(l1)\n",
    "        l2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(l2)\n",
    "    #     l2 = Dropout(0.7)(l2)\n",
    "\n",
    "        l3 = NiNBlock(3, [512, 512, 512], [1,1])(l2)\n",
    "\n",
    "        l4 = NiNBlock(3, [1024, 1024, 512,384], [1,1])(l3)\n",
    "        l5 = NiNBlock(3, [512, 512, 512], [2,2])(l4)\n",
    "        l5 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(l5)\n",
    "        l6 = Dense(1024)(l5)\n",
    "        l7 = Dense(1024)(l6)\n",
    "        #add dense according to attribute layer. (for each attribute 1 or 0)\n",
    "#         l8 = Dense(1)(l7)\n",
    "        l9 = Activation('softmax')(l7) # or sigmoid\n",
    "\n",
    "        model = Model(inputs=img, outputs=l9)\n",
    "        return model\n",
    "    img_rows = input_shape[0];\n",
    "    img_cols = input_shape[1];\n",
    "    rgb = input_shape[2];\n",
    "    model = get_model(img_rows,img_cols,rgb)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopSequence(Sequence):\n",
    "# class TopSequence():\n",
    "    def __init__(self, x, y, batch_size, img_size = [32,32,3], test_mode=False):\n",
    "        print(\"init\")\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.test_mode = test_mode\n",
    "        self.data_size = x.shape[0]\n",
    "        print(self.data_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        print(\"len\")\n",
    "        return self.data_size // self.batch_size\n",
    "\n",
    "    def __getitem__(self,batch_idx):\n",
    "        print(\"called\")\n",
    "        if (batch_idx + 1) * self.batch_size - 1 >= self.data_size:\n",
    "            batch_idx = np.random.randint(self.data_size - 1)\n",
    "\n",
    "        # Create empty arrays to contain batch of images and labels\n",
    "        batch_images = np.zeros((self.batch_size, self.img_size[0], self.img_size[1], self.img_size[2]))\n",
    "        batch_top_outer_category = np.zeros((self.batch_size,5), dtype=np.uint32)\n",
    "\n",
    "        for b in range(self.batch_size):\n",
    "            img_path = self.x[batch_idx * self.batch_size + b]\n",
    "            im = cv2.imread(img_path)\n",
    "            im = cv2.resize(im,(self.img_size[0], self.img_size[1]))\n",
    "            im = im / 255.0\n",
    "#             im = augment_image(im)\n",
    "#             im = im * 255.0\n",
    "\n",
    "            batch_images[b, :, :, :] = im                                                    #storing image\n",
    "            batch_top_outer_category[b, :] = np_utils.to_categorical(int(self.y[batch_idx * self.batch_size + b]), 5)\n",
    "        \n",
    "        batch_images = preprocess_input(batch_images)\n",
    "        print(batch_images.shape)\n",
    "        return batch_images, batch_top_outer_category#[batch_person_direction, batch_top_outer_category, batch_top_outer_neck_style, batch_top_outer_fit, batch_top_outer_formality, batch_top_outer_design, batch_top_outer_length, batch_top_outer_sleeve_length, batch_top_outer_reflection, batch_presence_of_top_inner, batch_top_inner_category, batch_top_inner_neck_style, batch_top_inner_fit, batch_top_inner_formality, batch_top_inner_design, batch_top_inner_length, batch_top_inner_sleeve_length, batch_top_inner_reflection, batch_top_outer_color, batch_top_inner_color]# + batch_top_outer_color + batch_top_inner_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "5\n",
      "len\n",
      "len\n",
      "Epoch 1/1\n",
      "called\n",
      "(5, 32, 32, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected top_outer_category_pred to have 4 dimensions, but got array with shape (5, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-84df04c7b745>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mtrain_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     epochs=nb_epoch)\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected top_outer_category_pred to have 4 dimensions, but got array with shape (5, 5)"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat, savemat\n",
    "img_rows, img_cols = 112, 112\n",
    "channel = 3\n",
    "num_classes = 18\n",
    "batch_size = 5\n",
    "nb_epoch = 1\n",
    "\n",
    "X_train = []\n",
    "X_valid = []\n",
    "Y_train = []\n",
    "Y_valid = []\n",
    "\n",
    "with open(\"top_outer_category_balanced_train.csv\") as file_obj:\n",
    "    reader = csv.DictReader(file_obj, delimiter=',')\n",
    "    for line in reader:\n",
    "        X_train.append(line['x'])\n",
    "        Y_train.append(line['y'])\n",
    "\n",
    "with open(\"top_outer_category_balanced_test.csv\") as file_obj:\n",
    "    reader = csv.DictReader(file_obj, delimiter=',')\n",
    "    for line in reader:\n",
    "        X_valid.append(line['x'])\n",
    "        Y_valid.append(line['y'])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_valid = np.array(X_valid)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_valid = np.array(Y_valid)\n",
    "\n",
    "model = densenet(num_classes, input_shape=(32,32,3))\n",
    "top_outter_category_layer = Dense(5, activation='softmax', name='top_outer_category_pred')(model.output)\n",
    "model = Model(model.input,top_outter_category_layer,name=\"final\")\n",
    "\n",
    "\n",
    "ada = Adam(lr = 0.0001,decay=0.0005)\n",
    "model.compile(loss=['categorical_crossentropy'],optimizer=ada,metrics=['accuracy'])\n",
    "\n",
    "#model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "\n",
    "train_seq = TopSequence(X_train[0:5], Y_train[0:5], batch_size, img_size=[32,32,3])\n",
    "#val_seq = TopSequence(X_valid[1:2], Y_valid[1:2], batch_size, img_size=[32,32,3])\n",
    "\n",
    "model.fit_generator(\n",
    "    train_seq,\n",
    "    steps_per_epoch=len(train_seq),\n",
    "    epochs=nb_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
